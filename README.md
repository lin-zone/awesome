# Awesome

## Scrapy Distributed

* [crawlab](https://github.com/crawlab-team/crawlab) - 基于Golang的分布式爬虫管理平台
* [Gerapy](https://github.com/Gerapy/Gerapy) - Distributed Crawler Management Framework Based on Scrapy, Scrapyd, Django and Vue.js
* [scrapydweb](https://github.com/my8100/scrapydweb) - ScrapydWeb: Web app for Scrapyd cluster management

## Scrapy Middleware

* [scrapy-mongodb](https://github.com/sebdah/scrapy-mongodb) - MongoDB pipeline for Scrapy
* [scrapy-splitvariants](https://github.com/scrapy-plugins/scrapy-splitvariants) - Scrapy spider middleware to split an item into multiple items using a multi-valued key
* [scrapy-proxies](https://github.com/aivarsk/scrapy-proxies) - Random proxy middleware for Scrapy
* [scrapy-fake-useragent](https://github.com/alecxe/scrapy-fake-useragent) - Random User-Agent middleware based on fake-useragent
* [scrapy-selenium](https://github.com/clemfromspace/scrapy-selenium) - Scrapy middleware to handle javascript pages using selenium
* [scrapy-crawlera](https://github.com/scrapy-plugins/scrapy-crawlera) - Crawlera middleware for Scrapy
* [crawlera](https://scrapinghub.com/crawlera) - The World's Smartest Proxy Network
* [scrapy-deltafetch](https://github.com/scrapy-plugins/scrapy-deltafetch) - Scrapy spider middleware to ignore requests to pages containing items seen in previous crawls
* [scrapy-random-useragent](https://github.com/cnu/scrapy-random-useragent) - Scrapy Middleware to set a random User-Agent for every Request.
* [scrapy-crawl-once](https://github.com/TeamHG-Memex/scrapy-crawl-once) - Scrapy middleware which allows to crawl only new content
* [scrapy-magicfields](https://github.com/scrapy-plugins/scrapy-magicfields) - Scrapy middleware to add extra fields to items, like timestamp, response fields, spider attributes etc.

## command line

* [cleo](https://github.com/sdispater/cleo) - Cleo allows you to create beautiful and testable command-line interfaces.

## HTML parser

* [scrapely](https://github.com/scrapy/scrapely) - A pure-python HTML screen-scraping library

## Crawler

* [Douyin-Bot](https://github.com/wangshub/Douyin-Bot) - Python 抖音机器人，论如何在抖音上找到漂亮小姐姐
* [SinaSpider](https://github.com/LiuXingMing/SinaSpider) - 新浪微博爬虫（Scrapy、Redis）

## Tools

* [qrcode](https://github.com/sylnsfar/qrcode) - Python 艺术二维码生成器

## utils

* [queuelib](https://github.com/scrapy/queuelib) - Collection of persistent (disk-based) queues
