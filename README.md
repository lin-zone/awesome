# Awesome

## Scrapy

* [crawlab](https://github.com/crawlab-team/crawlab) - 基于Golang的分布式爬虫管理平台

## Scrapy Middleware

* [scrapy-mongodb](https://github.com/sebdah/scrapy-mongodb) - MongoDB pipeline for Scrapy
* [scrapy-splitvariants](https://github.com/scrapy-plugins/scrapy-splitvariants) - Scrapy spider middleware to split an item into multiple items using a multi-valued key
* [scrapy-proxies](https://github.com/aivarsk/scrapy-proxies) - Random proxy middleware for Scrapy
* [scrapy-fake-useragent](https://github.com/alecxe/scrapy-fake-useragent) - Random User-Agent middleware based on fake-useragent
* [scrapy-selenium](https://github.com/clemfromspace/scrapy-selenium) - Scrapy middleware to handle javascript pages using selenium
* [scrapy-crawlera](https://github.com/scrapy-plugins/scrapy-crawlera) - Crawlera middleware for Scrapy
* [crawlera](https://scrapinghub.com/crawlera) - The World's Smartest Proxy Network
* [scrapy-deltafetch](https://github.com/scrapy-plugins/scrapy-deltafetch) - Scrapy spider middleware to ignore requests to pages containing items seen in previous crawls
* [scrapy-random-useragent(https://github.com/cnu/scrapy-random-useragent) - Scrapy Middleware to set a random User-Agent for every Request.
* [scrapy-crawl-once](https://github.com/TeamHG-Memex/scrapy-crawl-once) - Scrapy middleware which allows to crawl only new content
* [scrapy-magicfields](https://github.com/scrapy-plugins/scrapy-magicfields) - Scrapy middleware to add extra fields to items, like timestamp, response fields, spider attributes etc.
